{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from GPT2 import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda' #'cuda'\n",
    "\n",
    "model = GPT2Model(\n",
    "    vocab_size=30000,\n",
    "    layer_size=12,\n",
    "    block_size=1024,\n",
    "    embedding_dropout=0.0,\n",
    "    embedding_size=768,\n",
    "    num_attention_heads=12,\n",
    "    attention_dropout=0.0,\n",
    "    residual_dropout=0.0)\n",
    "\n",
    "state_dict = torch.load('save_distill.pth', map_location='cpu')\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = GPT2Tokenizer(\n",
    "    'GPT2/bpe/vocab.json',\n",
    "    'GPT2/bpe/chinese_vocab.model',\n",
    "    max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(text, max_len=10):\n",
    "    ids = tokenizer.encode(text)\n",
    "    input_id = torch.tensor((np.array(ids).reshape(1, -1).astype('int64'))).to(device)\n",
    "    output, cached_kvs = model(input_id, use_cache=True)\n",
    "    nid = int(np.argmax(output[0, -1].detach().cpu().numpy()))\n",
    "    ids += [nid]\n",
    "    out = [nid]\n",
    "    for i in range(max_len):\n",
    "        input_id = torch.tensor(np.array([nid]).reshape(1, -1).astype('int64')).to(device)\n",
    "        output, cached_kvs = model(input_id, cached_kvs, use_cache=True)\n",
    "        nid = int(np.argmax(output[0, -1].detach().cpu().numpy()))\n",
    "        ids += [nid]\n",
    "        if nid==3:\n",
    "            break\n",
    "        out.append(nid)\n",
    "    print(tokenizer.decode(out))\n",
    "\n",
    "def ask_question(question, max_len=10):\n",
    "    sample('''问题：中国的首都是哪里？\n",
    "    答案：北京。\n",
    "    问题：李白在哪个朝代？\n",
    "    答案：唐朝。\n",
    "    问题：%s\n",
    "    答案：''' % question, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.samplers import DistributedBatchSampler, RandomSampler\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "class CHIDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, split, tokenizer, ratio=1):\n",
    "        self.split = split\n",
    "        self.tokenizer = tokenizer\n",
    "        self.ratio = ratio\n",
    "        self.pad_id = tokenizer.encoder['<pad>']\n",
    "        self.eod_token = tokenizer.encoder['<eod>']\n",
    "\n",
    "        with open(data_path, \"r\") as f:\n",
    "            # cand_ids: the candidate label ids, namely, ids of \"0\", \"1\", ..., \"9\"\n",
    "            # data: preprocessed (tokenized) data\n",
    "            self.cand_ids, data = json.load(f)\n",
    "        self.samples, self.sizes = self.process(data)\n",
    "\n",
    "        self.max_size = max(self.sizes)\n",
    "\n",
    "    def process(self, data):\n",
    "        samples, sizes = [], []\n",
    "        for d in tqdm(data[:int(self.ratio * len(data))]):\n",
    "            # only use the loss of the last token\n",
    "            loss_mask = [0] * (len(d[\"sent\"]) - 2) + [1]\n",
    "\n",
    "            samples.append({\n",
    "                \"input_ids\": d[\"sent\"][:-1], # ids for the tokenized sentence\n",
    "                \"loss_mask\": loss_mask, # mask of the loss\n",
    "                \"labels\": d[\"sent\"][1:], # token labels of each sentence\n",
    "                \"truth\": d[\"truth\"], # labels if each sentence, should be an integer in [0, 9]\n",
    "            })\n",
    "            sizes.append(len(d[\"sent\"]) - 1)\n",
    "\n",
    "        return samples, sizes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sizes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.sizes[idx]\n",
    "\n",
    "    def collate(self, x):\n",
    "        bs = len(x)\n",
    "        samps = [s[0] for s in x]\n",
    "        sizes = [s[1] for s in x]\n",
    "\n",
    "        # fit to the max_size\n",
    "        max_size = self.max_size\n",
    "\n",
    "        # triangle attention mask\n",
    "        attn_mask = torch.tril(torch.ones((max_size, max_size))).unsqueeze(0)\n",
    "        position_ids = torch.arange(max_size, dtype=torch.long).unsqueeze(0).repeat(bs, 1)\n",
    "\n",
    "        # the data that need to go through the model\n",
    "        batch_sample = {\n",
    "            \"input_ids\": torch.ones(bs, max_size).long() * self.pad_id,\n",
    "            \"attention_mask\": attn_mask.unsqueeze(1),\n",
    "            \"position_ids\": position_ids,\n",
    "        }\n",
    "\n",
    "        # the data that do not need to go through the model\n",
    "        no_model_sample = {\n",
    "            \"labels\": torch.ones(bs, max_size).long() * self.pad_id,\n",
    "            \"truth\": torch.zeros(bs).long(),\n",
    "            \"loss_mask\": torch.zeros(bs, max_size).float()\n",
    "        }\n",
    "\n",
    "        for i, samp in enumerate(samps):\n",
    "            batch_sample[\"input_ids\"][i, :len(samp[\"input_ids\"])] = torch.tensor(samp[\"input_ids\"])\n",
    "            no_model_sample[\"labels\"][i, :len(samp[\"labels\"])] = torch.tensor(samp[\"labels\"])\n",
    "            no_model_sample[\"truth\"][i] = torch.tensor(samp[\"truth\"])\n",
    "            no_model_sample[\"loss_mask\"][i, :len(samp[\"loss_mask\"])] = torch.tensor(samp[\"loss_mask\"])\n",
    "\n",
    "        return batch_sample, no_model_sample\n",
    "\n",
    "\n",
    "def load_data(data_path, data_type, tokenizer, ratio=1):\n",
    "\n",
    "    # Dataset\n",
    "    filename = os.path.join(data_path, data_type + '.json')\n",
    "    dataset = CHIDDataset(filename, data_type, tokenizer, ratio=ratio)\n",
    "    \n",
    "    # Use a random sampler with distributed batch sampler.\n",
    "    if data_type == 'train':\n",
    "        sampler = RandomSampler(dataset)\n",
    "    else:\n",
    "        sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "    \n",
    "    # Torch dataloader.\n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       sampler=sampler,\n",
    "                                       num_workers=0,\n",
    "                                       pin_memory=True,\n",
    "                                       collate_fn=dataset.collate), dataset\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, device, mode=\"train\"):\n",
    "    model.train()\n",
    "    for batch, no_model_batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(device)\n",
    "        for k in no_model_batch.keys():\n",
    "            no_model_batch[k] = no_model_batch[k].to(device)\n",
    "\n",
    "        output = model(batch['input_ids'])\n",
    "        output = torch.sum(output * no_model_batch[\"loss_mask\"].unsqueeze(-1), 1) / torch.sum(no_model_batch[\"loss_mask\"], -1).unsqueeze(-1)\n",
    "\n",
    "        labels = no_model_batch[\"labels\"].float()\n",
    "        labels = (torch.sum(labels * no_model_batch[\"loss_mask\"], 1) / torch.sum(no_model_batch[\"loss_mask\"], -1)).long()\n",
    "\n",
    "        losses = loss_fcn(output.unsqueeze(1).contiguous().float(), labels.unsqueeze(1))\n",
    "        loss = torch.mean(losses)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, cand_ids, device, mode=\"dev\"):\n",
    "    model.eval()\n",
    "    all_truth, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch, no_model_batch in tqdm(dataloader, desc=\"Evaluating {}\".format(mode)):\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to(device)\n",
    "            for k in no_model_batch:\n",
    "                no_model_batch[k] = no_model_batch[k].to(device)\n",
    "\n",
    "            output = model(batch['input_ids'])\n",
    "            output = torch.sum(output * no_model_batch[\"loss_mask\"].unsqueeze(-1), 1) / torch.sum(no_model_batch[\"loss_mask\"], -1).unsqueeze(-1)\n",
    "\n",
    "            scores = output.view(-1, 30000)\n",
    "\n",
    "            truth = no_model_batch[\"truth\"]\n",
    "            truth = truth.view(-1)\n",
    "            scores = scores[:, cand_ids]\n",
    "\n",
    "            preds = torch.argmax(scores, dim=-1)\n",
    "\n",
    "            all_truth.extend(truth.detach().cpu().tolist())\n",
    "            all_preds.extend(preds.detach().cpu().tolist())\n",
    "        \n",
    "    acc = sum([int(p == l) for p, l in zip(all_preds, all_truth)]) / len(all_truth)\n",
    "    acc = torch.tensor(acc).to(device)\n",
    "\n",
    "    return acc, all_truth, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 577157/577157 [00:20<00:00, 28718.55it/s]\n",
      "100%|██████████| 23209/23209 [00:00<00:00, 80879.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, trainset = load_data('../nlpdata/data/chid', 'train', tokenizer)\n",
    "test_dataloadar, testset = load_data('../nlpdata/data/chid', 'test', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss_fcn = nn.CrossEntropyLoss()\n",
    "loss_fcn.to(device)\n",
    "\n",
    "import transformers\n",
    "optimizer = transformers.AdamW(model.parameters(), lr=1.5e-6, eps=1.0e-9)  # lr=1.5e-4, eps=1.0e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_ids = torch.tensor(testset.cand_ids).to(device)\n",
    "acc, all_truth, all_preds = evaluate(model, test_dataloadar, cand_ids, device, mode=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataloader, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"trained_fill.pth\")  # 只保存模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保险好。\n"
     ]
    }
   ],
   "source": [
    "ask_question('保险好吗？', max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集训,回来后,我就开始画了,当时画的是\n"
     ]
    }
   ],
   "source": [
    "sample('去北京画室参加', max_len=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5516efe75593d06eaf40bae3490a069baebb94ad14a4bb81cab04a47f7ae72c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('cpm': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
